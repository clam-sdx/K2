{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test set evaluation \n",
    "We now use top models from the grid search to deploy on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the below is similar to the code seen in \"protein-eval.py\", use the selected models in notebook #4 to hardcode model strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_list = [\"COLLAPSE\", \"ESM\", \"AA\"]\n",
    "test_metrics = [\"ap\"]\n",
    "metal = 'ZN'\n",
    "# hard coded for now from looking at top of ranked dataframe\n",
    "encoder_top_models = { \\\n",
    "    'COLLAPSE': ('k25_r4_cutoff8.00_alpha1.0000_tau4.00_lamnan.model', 0.95), \\\n",
    "    # 'COLLAPSE': ('k15_r1_cutoff8.00_alpha0.0100_tau0.00_lamnan.model', 0.8), \\\n",
    "    'ESM': ('k30_r2_cutoff6.00_alpha0.0100_tau0.00_lamnan.model', 0.1), \\\n",
    "    'AA': ('k21_r1_cutoff8.00_alpha0.010_tau1.00_lamnan.model', 0.5)}\n",
    "\n",
    "baseline_top_models = \\\n",
    "    {'COLLAPSE': ('COLLAPSE-ZN-8.0-0.0001-100', 0.7), \\\n",
    "    'ESM': ('ESM-ZN-6.0-0.001-500', 0.4), \\\n",
    "    'AA': ('AA-ZN-6.0-0.001-200', 0.5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def setup_figure(width=6, height=3):\n",
    "    sns.set(style='white')\n",
    "    sns.set_context('paper')\n",
    "    plt.figure(figsize=(width,height))\n",
    "pal = sns.color_palette('tab20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import test_eval, extract_params, get_test_metrics\n",
    "import utils\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = ['Attention', 'GNNExplainer', 'SHAP']\n",
    "base_df = []\n",
    "for encoder in encoder_list:\n",
    "    for baseline in baselines:\n",
    "        for model_thresh_pair in baseline_top_models[encoder]:\n",
    "            best_model, best_thresh = baseline_top_models[encoder]\n",
    "            results_dict = utils.deserialize(f'../data/baselines/{encoder}_{baseline}_test_results.pkl')\n",
    "            df = get_test_metrics(results_dict, encoder, best_model, best_thresh, test_metrics)\n",
    "            # add a \"method\" column to the df (K2, Attn, Prob)\n",
    "            df[\"method\"] = \"GAT+\"+baseline\n",
    "            base_df.append(df)\n",
    "base_df = pd.concat(base_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.groupby(['encoder', 'method']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from evaluation import compute_seg_all_configs\n",
    "\n",
    "# cache_dir = \"/dfs/scratch1/gmachi/gcp_backup/k2/\"\n",
    "# Gs_dir = \"/dfs/scratch1/gmachi/gcp_backup/data/tinycam/test/clean_Gs_\"\n",
    "# label_dict_path = \"/dfs/scratch1/gmachi/gcp_backup/k2/refined_label_dicts/refined_test_labeldict-\" \n",
    "# gts_path = \"/dfs/scratch1/gmachi/gcp_backup/data/tinycam/test/gt_graphs_\"\n",
    "\n",
    "# test_df = compute_seg_all_configs(encoder_top_models, cache_dir, Gs_dir, gts_path, label_dict_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the below cell takes about 8min to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = []\n",
    "for encoder, (model_str, threshold) in encoder_top_models.items():\n",
    "    results_cache_dir = f\"../data/{encoder}_{metal}_gridsearch_results/{encoder}-eval_results\"\n",
    "    model_cache_dir = f\"../data/{encoder}_{metal}_gridsearch_results/{encoder}-fitted_k2_models\"\n",
    "    processor_cache_dir = f\"../data/{encoder}_{metal}_gridsearch_results/{encoder}-fitted_k2_processors\"\n",
    "    linearized_cache_dir = f\"../data/{encoder}_{metal}_gridsearch_results/{encoder}-linearized_data\"\n",
    "\n",
    "    _,_,cutoff,_,_,_ = extract_params(model_str)\n",
    "\n",
    "    if encoder == 'AA':\n",
    "        g_encoder = 'COLLAPSE'\n",
    "    else:\n",
    "        g_encoder = encoder\n",
    "\n",
    "    G_dir = f\"../data/{g_encoder}_{metal}_{cutoff}_test_graphs_2\"\n",
    "\n",
    "    df = test_eval(model_str, threshold, test_metrics, model_cache_dir, processor_cache_dir, G_dir, gt_dir=None, label_dict=None, modality=\"graph\", arm=\"test\")\n",
    "    df['method'] = 'Prospector'\n",
    "    test_df.append(df)\n",
    "test_df = pd.concat(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([test_df, base_df])\n",
    "\n",
    "mean_df = combined_df.groupby(['encoder', 'method','regime', 'metric'])['value'].mean().reset_index()\n",
    "sem_df = combined_df.groupby(['encoder', 'method','regime', 'metric'])['value'].sem().reset_index()\n",
    "\n",
    "mean_pvt = mean_df.pivot(index=['encoder', 'method', 'regime'], columns='metric', values='value')\n",
    "mean_pvt = mean_pvt[test_metrics]\n",
    "\n",
    "sem_pvt = sem_df.pivot(index=['encoder', 'method', 'regime'], columns='metric', values='value')\n",
    "sem_pvt = sem_pvt[test_metrics]\n",
    "\n",
    "#Save dfs\n",
    "# mean_pvt.to_csv(f'../data/all_test_results_mean-{test_metrics[0]}.csv')\n",
    "# sem_pvt.to_csv(f'../data/all_test_results_sem-{test_metrics[0]}.csv')\n",
    "# combined_df.to_csv(f'../data/all_test_results_points-{test_metrics[0]}.csv') # graph-level results\n",
    "# test_df.to_csv(f'../data/k2_test_results_points-{test_metrics[0]}.csv')  # k2 only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Properties vs performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import compute_test_mrds, compute_test_rps, compute_test_mcs, compute_test_ccs\n",
    "\n",
    "G_dir = f\"../data/COLLAPSE_ZN_8.0_test_graphs_2\"\n",
    "rps_dict = compute_test_rps(G_dir, gt_key='gt')\n",
    "mrds_dict = compute_test_mrds(G_dir, gt_key='gt')\n",
    "ccs_dict = compute_test_ccs(G_dir, gt_key='gt')\n",
    "mcs_dict = compute_test_mcs(G_dir, gt_key='gt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['rp'] = test_df['datum_id'].map(rps_dict)\n",
    "test_df['mrd'] = test_df['datum_id'].map(mrds_dict)\n",
    "test_df['ccs'] = test_df['datum_id'].map(ccs_dict)\n",
    "test_df['mcs'] = test_df['datum_id'].map(mcs_dict)\n",
    "test_df['srp'] = test_df['rp'] / test_df['ccs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.reset_index(drop=True).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def movingaverage(interval, window_size):\n",
    "    window= np.ones(int(window_size))/float(window_size)\n",
    "    return np.convolve(interval, window, 'full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_means = test_df.sort_values('rp').groupby('encoder').apply(lambda x: movingaverage(x['value'], 20))\n",
    "mean_data = []\n",
    "for enc, df in test_df.sort_values('rp').groupby('encoder'):\n",
    "    mean_data.extend(list(zip(df['rp'], running_means[enc], [enc]*len(df))))\n",
    "mean_data = pd.DataFrame(mean_data, columns=['rp', 'value', 'encoder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met = test_metrics[0]\n",
    "setup_figure(5,3.5)\n",
    "g = sns.scatterplot(data=test_df, x=\"rp\", y=\"value\", hue=\"encoder\", size=\"ccs\", sizes=(10, 100), alpha=0.3)\n",
    "sns.lineplot(data=mean_data.reset_index(), x='rp', y='value', hue='encoder', hue_order=['COLLAPSE', 'ESM', 'AA'])\n",
    "# g = sns.scatterplot(data=test_df, x=\"rp\", y=\"value\", hue=\"encoder\", alpha=0.4, s=100)\n",
    "g.set_xscale(\"log\")\n",
    "# g.set_yscale(\"log\")\n",
    "sns.move_legend(g, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "g.set_xlabel('Region Prevalence', fontsize=13)\n",
    "g.set_ylabel('Localization AUPRC', fontsize=13)\n",
    "g.tick_params(labelsize=13)\n",
    "g.set_title(\"MetalPDB\", fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../data/figures/enc_vs_prevalence_scatter_\" + met + \".png\", dpi=300, format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met = test_metrics[0]\n",
    "setup_figure(5,3.5)\n",
    "# g = sns.scatterplot(data=test_df, x=\"rp\", y=\"value\", hue=\"encoder\", size=\"ccs\", sizes=(10, 100), alpha=0.3)\n",
    "g = sns.lineplot(data=mean_data.reset_index(), x='rp', y='value', hue='encoder', hue_order=['COLLAPSE', 'ESM', 'AA'])\n",
    "# g = sns.scatterplot(data=test_df, x=\"rp\", y=\"value\", hue=\"encoder\", alpha=0.4, s=100)\n",
    "g.set_xscale(\"log\")\n",
    "# g.set_yscale(\"log\")\n",
    "sns.move_legend(g, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "g.set_xlabel('Region Prevalence', fontsize=13)\n",
    "g.set_ylabel('Localization AUPRC', fontsize=13)\n",
    "g.tick_params(labelsize=13)\n",
    "g.set_title(\"MetalPDB\", fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../data/figures/enc_vs_prevalence_line_\" + met + \".png\", dpi=300, format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_means = test_df.sort_values('mrd').groupby('encoder').apply(lambda x: movingaverage(x['value'], 20))\n",
    "mean_data = []\n",
    "for enc, df in test_df.sort_values('mrd').groupby('encoder'):\n",
    "    mean_data.extend(list(zip(df['mrd'], running_means[enc], [enc]*len(df))))\n",
    "mean_data = pd.DataFrame(mean_data, columns=['mrd', 'value', 'encoder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_figure(5,3.5)\n",
    "g = sns.scatterplot(data=test_df, x=\"mrd\", y=\"value\", hue=\"encoder\", size=\"ccs\", sizes=(10, 100), alpha=0.3)\n",
    "sns.lineplot(data=mean_data.reset_index(), x='mrd', y='value', hue='encoder', hue_order=['COLLAPSE', 'ESM', 'AA'])\n",
    "# g = sns.scatterplot(data=test_df, x=\"rp\", y=\"value\", hue=\"encoder\", alpha=0.4, s=100)\n",
    "g.set_xscale(\"log\")\n",
    "# g.set_yscale(\"log\")\n",
    "g.set_xlim(0.1, 10)\n",
    "sns.move_legend(g, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "g.set_xlabel('Mean Region Dispersion', fontsize=13)\n",
    "g.set_ylabel('Segmentation AUPRC', fontsize=13)\n",
    "g.tick_params(labelsize=13)\n",
    "g.set_title(\"MetalPDB\", fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../data/figures/enc_vs_mrd_scatter_\" + met + \".png\", dpi=300, format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_figure(5,3.5)\n",
    "# g = sns.scatterplot(data=test_df, x=\"mrd\", y=\"value\", hue=\"encoder\", size=\"ccs\", sizes=(10, 100), alpha=0.3)\n",
    "g=sns.lineplot(data=mean_data.reset_index(), x='mrd', y='value', hue='encoder', hue_order=['COLLAPSE', 'ESM', 'AA'])\n",
    "# g = sns.scatterplot(data=test_df, x=\"rp\", y=\"value\", hue=\"encoder\", alpha=0.4, s=100)\n",
    "g.set_xscale(\"log\")\n",
    "# g.set_yscale(\"log\")\n",
    "g.set_xlim(0.1, 10)\n",
    "sns.move_legend(g, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "g.set_xlabel('Mean Region Dispersion', fontsize=13)\n",
    "g.set_ylabel('Segmentation AUPRC', fontsize=13)\n",
    "g.tick_params(labelsize=13)\n",
    "g.set_title(\"MetalPDB\", fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../data/figures/enc_vs_mrd_line_\" + met + \".png\", dpi=300, format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.scatterplot(data=test_df, x=\"mcs\", y=\"value\", hue=\"encoder\", size=\"ccs\", sizes=(40, 300), alpha=0.4)\n",
    "# # g = sns.scatterplot(data=test_df, x=\"rp\", y=\"value\", hue=\"encoder\", alpha=0.4, s=100)\n",
    "# g.set_xscale(\"log\")\n",
    "# g.set_yscale(\"log\")\n",
    "# _ = g.set(xlabel=\"Mean Component Size\", ylabel=\"Segmentation AUPRC\")\n",
    "# g.set_title(\"Impact of test-set MCS for segmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.scatterplot(data=test_df, x=\"rp\", y=\"value\", hue=\"encoder\", size=\"mrd\", sizes=(40, 300), alpha=0.4)\n",
    "# # g = sns.scatterplot(data=test_df, x=\"rp\", y=\"value\", hue=\"encoder\", alpha=0.4, s=100)\n",
    "# g.set_xscale(\"log\")\n",
    "# g.set_yscale(\"log\")\n",
    "# _ = g.set(xlabel=\"Region Prevalence\", ylabel=\"Segmentation AUPRC\")\n",
    "# g.set_title(\"Impact of test-set RP for segmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plotting test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import utils\n",
    "\n",
    "# combined_df = pd.read_csv(\"/home/k2/K2/src/outputs/k2-test/all_test_results_points.csv\")\n",
    "# combined_df = pd.read_csv(\"/dfs/scratch1/gmachi/gcp_backup/k2/k2-test/all_test_results_points.csv\")\n",
    "\n",
    "# test_df['method'] = ['Prospector']*len(test_df) #+ ['GAT+Explainer']*len(base_df)\n",
    "combined_df = pd.concat([test_df, base_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.method.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for met in test_metrics:\n",
    "    subdf = combined_df[combined_df.metric == met].reset_index()\n",
    "    plt.clf()\n",
    "    # p=sns.color_palette(\"Set1\")\n",
    "    # colors at: https://xkcd.com/color/rgb/\n",
    "    p=sns.xkcd_palette([\"cerulean\",\"lavender\",\"celadon\",\"sage\",\"mahogany\",\"goldenrod\",\"violet\",\"fuchsia\"])\n",
    "    if met in ['auprc', 'ap', 'auroc']:\n",
    "        setup_figure(4.5,3)\n",
    "        hue_order = ['GAT+Attention', 'Prospector', 'GAT+GNNExplainer', 'GAT+SHAP']\n",
    "        ax = sns.barplot(data=subdf[subdf.regime == 'all'], palette=p, x='encoder', y='value', hue='method', hue_order=hue_order, orient='vertical', errorbar='se', capsize=0.05, errwidth=1.0, linewidth=1, edgecolor=\"k\")\n",
    "        sns.stripplot(data=subdf[subdf.regime == 'all'], palette=p, x='encoder', y='value',  hue='method', hue_order=hue_order, orient='vertical', dodge=True, alpha=0.1, linewidth=0.5, ax=ax, legend=False)\n",
    "        plt.title(\"MetalPDB\", fontsize=15)\n",
    "        ax.set_ylabel(f'Localization {met}', fontsize=13)\n",
    "        if met == 'ap':\n",
    "            ax.set_ylabel(f'Localization Average Precision', fontsize=13)\n",
    "        ax.set_xlabel('')\n",
    "        ax.tick_params(labelsize=11)\n",
    "        for p in ax.patches:\n",
    "            y = p.get_height()\n",
    "            print(y)\n",
    "        plt.legend(loc=(1.01,0.7))\n",
    "    elif met == 'precision':\n",
    "        setup_figure(3,3)\n",
    "        hue_order = ['GAT+Attention', 'Prospector', 'GAT+GNNExplainer', 'GAT+SHAP']\n",
    "        ax = sns.barplot(data=subdf[subdf.regime == 'class-1'], palette=p, x='encoder', y='value', hue='method', hue_order=hue_order, orient='vertical', errorbar='se', capsize=0.05, errwidth=1.0, linewidth=1, edgecolor=\"k\")\n",
    "        sns.stripplot(data=subdf[subdf.regime == 'class-1'], palette=p, x='encoder', y='value',  hue='method', hue_order=hue_order, orient='vertical', dodge=True, alpha=0.1, linewidth=0.5, ax=ax, legend=False)\n",
    "        plt.title(\"MetalPDB\", fontsize=15)\n",
    "        ax.set_ylabel('Precision', fontsize=13)\n",
    "        ax.set_xlabel('')\n",
    "        ax.tick_params(labelsize=11)\n",
    "        for p in ax.patches:\n",
    "            y = p.get_height()\n",
    "            print(y)\n",
    "        plt.legend(loc='upper left')\n",
    "    # else:\n",
    "    #     fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(6, 3), sharey=True, gridspec_kw={'wspace': 0})\n",
    "    #     sns.barplot(data=subdf[subdf['regime'] == 'class-1'], x='value', y='encoder', hue='method', orient='horizontal', dodge=True, ax=ax2, errorbar='se', capsize=0.05, errwidth=1.0, linewidth=1, edgecolor=\"w\")\n",
    "    #     sns.stripplot(data=subdf[subdf['regime'] == 'class-1'], x='value', y='encoder', hue='method', orient='horizontal', dodge=True, alpha=0.1, linewidth=0.5, ax=ax2, legend=False)\n",
    "    #     # ax1.yaxis.set_label_position('left')\n",
    "\n",
    "    #     ax2.set_title('  '+'class-1', loc='left')\n",
    "    #     ax2.set_ylabel('')\n",
    "    #     ax2.set_yticklabels([])\n",
    "    #     ax2.legend_.remove()\n",
    "    \n",
    "    #     sns.barplot(data=subdf[subdf['regime'] == 'all'], x='value', y='encoder', hue='method', orient='horizontal', dodge=True, ax=ax1, errorbar='se', capsize=0.05, errwidth=1.0, linewidth=1, edgecolor=\"k\")\n",
    "    #     sns.stripplot(data=subdf[subdf['regime'] == 'all'], x='value', y='encoder', hue='method', orient='horizontal', dodge=True, alpha=0.1, linewidth=0.5, ax=ax1, legend=False)\n",
    "    #     ax1.legend_.remove()\n",
    "    \n",
    "    #     # optionally use the same scale left and right\n",
    "    #     xmax = max(ax1.get_xlim()[1], ax2.get_xlim()[1])\n",
    "    #     ax1.set_xlim(xmax=xmax)\n",
    "    #     ax2.set_xlim(xmax=xmax)\n",
    "\n",
    "    #     ax1.invert_xaxis()  # reverse the direction\n",
    "    #     ax1.tick_params(axis='y', labelleft=True, left=True, labelright=False, right=False)\n",
    "    #     ax1.set_ylabel('')\n",
    "    #     ax1.set_title('all data'+'  ', loc='right')\n",
    "\n",
    "    #     plt.legend(loc=(-1.01,1.02))\n",
    "    #     fig.suptitle(met, fontsize=15)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\"../data/figures/k2-vs-baseline_\" + met + \".png\", dpi=2000, format='png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdf[subdf.regime == 'all'].groupby(['encoder','method'])['value'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[combined_df.regime == 'all'].groupby(['encoder','method'])['value'].sem()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.640309 - 0.376692"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "k2",
   "language": "python",
   "name": "k2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

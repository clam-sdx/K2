{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('k15_r0_cutoff6.00_alpha0.500_tau0.00_lamnan.model',\n",
       " 0.9,\n",
       " 0.3041668074688543,\n",
       " 0.3041668074688543)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model_selection import top_model_confusion\n",
    "from utils import serialize, deserialize, serialize_model, deserialize_model\n",
    "\n",
    "encoder = 'COLLAPSE'\n",
    "metal = 'ZN'\n",
    "metric_str = \"precision\"\n",
    "results_cache_dir = f\"../data/{encoder}_{metal}_gridsearch_results/{encoder}-eval_results\"\n",
    "model_cache_dir = f\"../data/{encoder}_{metal}_gridsearch_results/{encoder}-fitted_k2_models\"\n",
    "linearized_cache_dir = f\"../data/{encoder}_{metal}_gridsearch_results/{encoder}-linearized_data\"\n",
    "\n",
    "top_model_confusion(metric_str,results_cache_dir, model_cache_dir, eval_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/results/ZN_confusion_all_train_models.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m confusion_all_models \u001b[39m=\u001b[39m deserialize(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m../data/results/\u001b[39;49m\u001b[39m{\u001b[39;49;00mmetal\u001b[39m}\u001b[39;49;00m\u001b[39m_confusion_all_train_models.pkl\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m confusion_class1_models \u001b[39m=\u001b[39m deserialize(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m../data/results/\u001b[39m\u001b[39m{\u001b[39;00mmetal\u001b[39m}\u001b[39;00m\u001b[39m_confusion_class1_train_models.pkl\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m datum_level_models \u001b[39m=\u001b[39m deserialize(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m../data/results/\u001b[39m\u001b[39m{\u001b[39;00mmetal\u001b[39m}\u001b[39;00m\u001b[39m_datum_level_train_models.pkl\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/oak/stanford/groups/rbaltman/aderry/K2/src/utils.py:30\u001b[0m, in \u001b[0;36mdeserialize\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeserialize\u001b[39m(path):\n\u001b[0;32m---> 30\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(path, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m fh:\n\u001b[1;32m     31\u001b[0m         \u001b[39mreturn\u001b[39;00m pickle\u001b[39m.\u001b[39mload(fh)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/results/ZN_confusion_all_train_models.pkl'"
     ]
    }
   ],
   "source": [
    "confusion_all_models = deserialize(f\"../data/results/{metal}_confusion_all_train_models.pkl\")\n",
    "confusion_class1_models = deserialize(f\"../data/results/{metal}_confusion_class1_train_models.pkl\")\n",
    "datum_level_models = deserialize(f\"../data/results/{metal}_datum_level_train_models.pkl\")\n",
    "continuous_avg_models = deserialize(f\"../data/results/{metal}_continuous_avg_train_models.pkl\")\n",
    "continuous_iid_models = deserialize(f\"../data/results/{metal}_continuous_iid_train_models.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'msd': ('k20_r0_cutoff8.00_alpha0.001_tau2.00_lamnan.model', 0.0),\n",
       " 'specificity': ('k20_r1_cutoff6.00_alpha0.100_tau2.00_lamnan.model', 0.5),\n",
       " 'precision': ('k20_r2_cutoff6.00_alpha0.100_tau0.00_lamnan.model', 0.9),\n",
       " 'fnr': ('k20_r1_cutoff6.00_alpha0.100_tau2.00_lamnan.model', 0.5),\n",
       " 'fdr': ('k20_r2_cutoff4.00_alphanan_taunan_lam0.50.model', 0.9),\n",
       " 'recall': ('k20_r1_cutoff6.00_alpha0.100_tau2.00_lamnan.model', 0.0),\n",
       " 'accuracy': ('k20_r1_cutoff6.00_alpha0.100_tau2.00_lamnan.model', 0.5),\n",
       " 'balanced_acc': ('k20_r0_cutoff4.00_alphanan_taunan_lam0.50.model', 0.6),\n",
       " 'correlation': ('k20_r4_cutoff6.00_alpha0.001_tau0.00_lamnan.model', 0.9),\n",
       " 'threat_score': ('k20_r4_cutoff6.00_alpha0.001_tau0.00_lamnan.model', 0.9),\n",
       " 'prevalence': ('k20_r1_cutoff6.00_alpha0.100_tau2.00_lamnan.model', 0.0),\n",
       " 'dice': ('k20_r4_cutoff6.00_alpha0.001_tau0.00_lamnan.model', 0.9),\n",
       " 'jaccard': ('k20_r4_cutoff6.00_alpha0.001_tau0.00_lamnan.model', 0.9)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_class1_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_selection import k_hop_precision\n",
    "for encoder in ['COLLAPSE', 'ESM', 'AA']:\n",
    "    results_cache_dir = f\"../data/{encoder}_{metal}_gridsearch_results/{encoder}-eval_results\"\n",
    "    model_cache_dir = f\"../data/{encoder}_{metal}_gridsearch_results/{encoder}-fitted_k2_models\"\n",
    "    linearized_cache_dir = f\"../data/{encoder}_{metal}_gridsearch_results/{encoder}-linearized_data\"\n",
    "    graph_base_dir = f\"../data/COLLAPSE_{metal}_cutoff_train_graphs\"\n",
    "\n",
    "    results = k_hop_precision('protein', results_cache_dir, linearized_cache_dir, model_cache_dir, graph_base_dir, eval_class='both')\n",
    "    \n",
    "    print(encoder, results)\n",
    "    \"\"\"\n",
    "    \n",
    "for encoder in ['COLLAPSE', 'ESM', 'AA']:\n",
    "    results_cache_dir = f\"../data/{encoder}_{metal}_gridsearch_results/{encoder}-eval_results\"\n",
    "    model_cache_dir = f\"../data/{encoder}_{metal}_gridsearch_results/{encoder}-fitted_k2_models\"\n",
    "    linearized_cache_dir = f\"../data/{encoder}_{metal}_gridsearch_results/{encoder}-linearized_data\"\n",
    "    graph_base_dir = f\"../data/{encoder}_{metal}_cutoff_train_graphs\"\n",
    "\n",
    "    results = k_hop_precision('protein', results_cache_dir, linearized_cache_dir, model_cache_dir, graph_base_dir, eval_class=1)\n",
    "    print(encoder, results)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msd\n",
      "('k20_r0_cutoff8.00_alpha0.001_tau2.00_lamnan.model', '>', 361.22301951779565)\n",
      "specificity\n",
      "('k10_r0_cutoff4.00_alpha0.001_tau0.00_lamnan.model', 1.0, 1.0)\n",
      "precision\n",
      "('k20_r2_cutoff6.00_alpha0.100_tau0.00_lamnan.model', 0.9, 0.027639492988932958)\n",
      "fnr\n",
      "('k10_r0_cutoff4.00_alpha0.001_tau0.00_lamnan.model', 1.0, 0.48679678530424797)\n",
      "fdr\n",
      "('k15_r1_cutoff4.00_alphanan_taunan_lam0.50.model', 0.9, 0.9976602850353525)\n",
      "recall\n",
      "('k20_r1_cutoff6.00_alpha0.100_tau2.00_lamnan.model', 0.0, 1.0)\n",
      "accuracy\n",
      "('k10_r0_cutoff4.00_alpha0.001_tau0.00_lamnan.model', 1.0, 0.9929412145133447)\n",
      "balanced_acc\n",
      "('k20_r2_cutoff6.00_alpha0.100_tau0.00_lamnan.model', 0.9, 0.5104395595671256)\n",
      "correlation\n",
      "('k20_r0_cutoff8.00_alpha0.001_tau0.00_lamnan.model', 0.9, 0.03524971449809501)\n",
      "threat_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/oak/stanford/groups/rbaltman/aderry/K2/src/metrics.py:104: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return tp / (tp + fn + fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('k20_r0_cutoff8.00_alpha0.001_tau0.00_lamnan.model', 0.9, 0.018289480717047984)\n",
      "prevalence\n",
      "('k10_r0_cutoff4.00_alpha0.001_tau0.00_lamnan.model', 0.0, 0.007058785486655712)\n",
      "dice\n",
      "('k15_r1_cutoff4.00_alpha0.100_tau2.00_lamnan.model', '<', 0.5132626435597806)\n",
      "jaccard\n",
      "('k15_r1_cutoff4.00_alpha0.100_tau2.00_lamnan.model', '<', 0.5132331635114069)\n"
     ]
    }
   ],
   "source": [
    "valid_metrics = [\"msd\", \"specificity\", \"precision\", \"fnr\", \"fdr\", \"recall\", \"accuracy\", \"balanced_acc\", \"correlation\", \"threat_score\", \"prevalence\", \"dice\", \"jaccard\"]\n",
    "for metric_str in valid_metrics:\n",
    "    print(metric_str)\n",
    "    results = top_model_confusion(metric_str,results_cache_dir, model_cache_dir)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msd\n",
      "('k20_r0_cutoff8.00_alpha0.001_tau2.00_lamnan.model', '>', 343.8249440715884)\n",
      "specificity\n",
      "('k10_r0_cutoff4.00_alpha0.001_tau0.00_lamnan.model', 1.0, 1.0)\n",
      "precision\n",
      "('k10_r0_cutoff4.00_alpha0.001_tau0.00_lamnan.model', 0.0, 0.0)\n",
      "fnr\n",
      "('k10_r0_cutoff4.00_alpha0.001_tau0.00_lamnan.model', 0.0, 0.0)\n",
      "fdr\n",
      "('k10_r0_cutoff4.00_alpha0.001_tau0.00_lamnan.model', 0.0, 1.0)\n",
      "recall\n",
      "('k10_r0_cutoff4.00_alpha0.001_tau0.00_lamnan.model', 0.0, 1.0)\n",
      "accuracy\n",
      "('k10_r0_cutoff4.00_alpha0.001_tau0.00_lamnan.model', 1.0, 1.0)\n",
      "balanced_acc\n",
      "('k10_r0_cutoff4.00_alpha0.001_tau0.00_lamnan.model', 0.0, 0.5)\n",
      "correlation\n",
      "('k10_r0_cutoff4.00_alpha0.001_tau0.00_lamnan.model', 0.0, 0.0)\n",
      "threat_score\n",
      "('k10_r0_cutoff4.00_alpha0.001_tau0.00_lamnan.model', 0.0, 0.0)\n",
      "prevalence\n",
      "('k10_r0_cutoff4.00_alpha0.001_tau0.00_lamnan.model', 0.0, 0.0)\n",
      "dice\n",
      "('k10_r0_cutoff4.00_alpha0.001_tau0.00_lamnan.model', 1.0, 1.0)\n",
      "jaccard\n",
      "('k10_r0_cutoff4.00_alpha0.001_tau0.00_lamnan.model', 1.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "valid_metrics = [\"msd\", \"specificity\", \"precision\", \"fnr\", \"fdr\", \"recall\", \"accuracy\", \"balanced_acc\", \"correlation\", \"threat_score\", \"prevalence\", \"dice\", \"jaccard\"]\n",
    "for metric_str in valid_metrics:\n",
    "    print(metric_str)\n",
    "    results = top_model_confusion(metric_str, results_cache_dir, model_cache_dir, eval_class=0)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msd\n",
      "('k15_r2_cutoff6.00_alpha0.100_tau0.00_lamnan.model', 0.0, 315.8590909090909, 315.8590909090909)\n",
      "specificity\n",
      "('k25_r4_cutoff4.00_alpha10000000000.000_tau2.00_lamnan.model', 1.0, 1.0, 0.7515132105463032)\n",
      "precision\n",
      "('k15_r0_cutoff6.00_alpha0.500_tau0.00_lamnan.model', 0.9, 0.3041668074688543, 0.3041668074688543)\n",
      "fnr\n",
      "('k25_r4_cutoff4.00_alpha10000000000.000_tau2.00_lamnan.model', 1.0, 1.0, 0.9757319223985891)\n",
      "fdr\n",
      "('k15_r4_cutoff4.00_alphanan_taunan_lam0.50.model', 0.5, 0.9832821100673487, 0.9832821100673487)\n",
      "recall\n",
      "('k20_r4_cutoff4.00_alpha0.001_tau0.00_lamnan.model', 0.0, 1.0, 1.0)\n",
      "accuracy\n",
      "('k25_r0_cutoff4.00_alpha0.010_tau2.00_lamnan.model', 0.9, 0.9890565010244482, 0.6742095176662541)\n",
      "balanced_acc\n",
      "('k25_r0_cutoff4.00_alphanan_taunan_lam0.50.model', 0.5, 0.6824292907063454, 0.20249396245272494)\n",
      "correlation\n",
      "('k20_r0_cutoff4.00_alpha0.001_tau0.00_lamnan.model', 0.9, 0.283302755744555, 0.43019888279702956)\n",
      "threat_score\n",
      "('k25_r0_cutoff4.00_alpha0.010_tau2.00_lamnan.model', 0.9, 0.2504271637783224, 0.2504271637783224)\n",
      "prevalence\n",
      "('k25_r4_cutoff4.00_alpha10000000000.000_tau2.00_lamnan.model', 0.0, 0.021490169022734273, 0.0)\n",
      "dice\n",
      "('k20_r0_cutoff4.00_alpha0.001_tau0.00_lamnan.model', 0.9, 0.2816072991487391, 0.2816072991487391)\n",
      "jaccard\n",
      "('k25_r0_cutoff4.00_alpha0.010_tau2.00_lamnan.model', 0.9, 0.2504271637783224, 0.2504271637783224)\n"
     ]
    }
   ],
   "source": [
    "valid_metrics = [\"msd\", \"specificity\", \"precision\", \"fnr\", \"fdr\", \"recall\", \"accuracy\", \"balanced_acc\", \"correlation\", \"threat_score\", \"prevalence\", \"dice\", \"jaccard\"]\n",
    "for metric_str in valid_metrics:\n",
    "    print(metric_str)\n",
    "    results = top_model_confusion(metric_str, results_cache_dir, model_cache_dir, eval_class=1)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auroc\n",
      "('k15_r0_cutoff4.00_alpha0.500_tau1.00_lamnan.model', 0.6417658365026786)\n",
      "auprc\n",
      "('k15_r0_cutoff4.00_alpha0.500_tau1.00_lamnan.model', 0.7503116923180316)\n",
      "ap\n",
      "('k15_r1_cutoff4.00_alpha0.001_tau2.00_lamnan.model', 0.6186558235373336)\n"
     ]
    }
   ],
   "source": [
    "from model_selection import top_model_preds\n",
    "valid_metrics = [\"auroc\", \"auprc\", \"ap\"]\n",
    "for metric_str in valid_metrics:\n",
    "    print(metric_str)\n",
    "    results = top_model_preds(metric_str, results_cache_dir, model_cache_dir)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auroc\n",
      "('k30_r0_cutoff4.00_alphanan_taunan_lam0.50.model', 0.6973103715675234)\n",
      "auprc\n",
      "('k15_r0_cutoff4.00_alpha0.500_tau1.00_lamnan.model', 0.623781770088546)\n",
      "ap\n",
      "('k30_r0_cutoff4.00_alpha10000000000.000_tau0.00_lamnan.model', 0.28177340947313906)\n"
     ]
    }
   ],
   "source": [
    "from model_selection import top_model_continuous_avg\n",
    "valid_metrics = [\"auroc\", \"auprc\", \"ap\"]\n",
    "for metric_str in valid_metrics:\n",
    "    print(metric_str)\n",
    "    results = top_model_continuous_avg(metric_str, results_cache_dir, model_cache_dir)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auroc\n",
      "('k15_r0_cutoff4.00_alpha0.500_tau1.00_lamnan.model', 0.722221562467037)\n",
      "auprc\n",
      "('k15_r0_cutoff4.00_alpha0.500_tau1.00_lamnan.model', 0.4308754654861674)\n",
      "ap\n",
      "('k25_r0_cutoff4.00_alpha0.010_tau2.00_lamnan.model', 0.293951822492335)\n"
     ]
    }
   ],
   "source": [
    "from model_selection import top_model_continuous_iid\n",
    "valid_metrics = [\"auroc\", \"auprc\", \"ap\"]\n",
    "for metric_str in valid_metrics:\n",
    "    print(metric_str)\n",
    "    results = top_model_continuous_iid(metric_str, model_cache_dir, linearized_cache_dir)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = 'COLLAPSE'\n",
    "metal = 'ZN'\n",
    "\n",
    "results_cache_dir = f\"../data/{encoder}_{metal}_baseline-GAT_gridsearch_results/{encoder}-eval_results\"\n",
    "model_cache_dir = f\"../data/{encoder}_{metal}_baseline-GAT_gridsearch_results/{encoder}-fitted_k2_models\"\n",
    "linearized_cache_dir = f\"../data/{encoder}_{metal}_baseline-GAT_gridsearch_results/{encoder}-linearized_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msd\n",
      "('COLLAPSE-ZN-6.0-1e-05', 0.0, 151.0, 151.0)\n",
      "specificity\n",
      "('COLLAPSE-ZN-6.0-1e-05', 0.8, 1.0, 1.0)\n",
      "precision\n",
      "('COLLAPSE-ZN-6.0-1e-05', 0.0, 0.0, 0.0)\n",
      "fnr\n",
      "('COLLAPSE-ZN-6.0-1e-05', 0.0, 0.0, 0.0)\n",
      "fdr\n",
      "('COLLAPSE-ZN-6.0-1e-05', 0.0, 1.0, 1.0)\n",
      "recall\n",
      "('COLLAPSE-ZN-6.0-1e-05', 0.0, 1.0, 0.0)\n",
      "accuracy\n",
      "('COLLAPSE-ZN-6.0-1e-05', 0.8, 1.0, 1.0)\n",
      "balanced_acc\n",
      "('COLLAPSE-ZN-6.0-1e-05', 0.0, nan, nan)\n",
      "correlation\n",
      "('COLLAPSE-ZN-6.0-1e-05', 0.0, 0.0, 0.0)\n",
      "threat_score\n",
      "('COLLAPSE-ZN-6.0-1e-05', 0.0, 0.0, 0.0)\n",
      "prevalence\n",
      "('COLLAPSE-ZN-6.0-1e-05', 0.0, 0.0, 0.0)\n",
      "dice\n",
      "('COLLAPSE-ZN-6.0-1e-05', 0.8, 1.0, 1.0)\n",
      "jaccard\n",
      "('COLLAPSE-ZN-6.0-1e-05', 0.8, 1.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "valid_metrics = [\"msd\", \"specificity\", \"precision\", \"fnr\", \"fdr\", \"recall\", \"accuracy\", \"balanced_acc\", \"correlation\", \"threat_score\", \"prevalence\", \"dice\", \"jaccard\"]\n",
    "for metric_str in valid_metrics:\n",
    "    print(metric_str)\n",
    "    results = top_model_confusion(metric_str,results_cache_dir, model_cache_dir)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msd\n",
      "0\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'model_cms' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric_str \u001b[38;5;129;01min\u001b[39;00m valid_metrics:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(metric_str)\n\u001b[0;32m----> 4\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mtop_model_confusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetric_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_cache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_cache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(results)\n",
      "File \u001b[0;32m/oak/stanford/groups/rbaltman/aderry/K2/src/model_selection.py:53\u001b[0m, in \u001b[0;36mtop_model_confusion\u001b[0;34m(metric_str, results_cache_dir, model_cache_dir, eval_class, return_all)\u001b[0m\n\u001b[1;32m     50\u001b[0m     N \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# now average over all graphs\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m thresh \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel_cms\u001b[49m\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     54\u001b[0m     model_cms[thresh] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m N\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# get top score and threshold\u001b[39;00m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'model_cms' referenced before assignment"
     ]
    }
   ],
   "source": [
    "valid_metrics = [\"msd\", \"specificity\", \"precision\", \"fnr\", \"fdr\", \"recall\", \"accuracy\", \"balanced_acc\", \"correlation\", \"threat_score\", \"prevalence\", \"dice\", \"jaccard\"]\n",
    "for metric_str in valid_metrics:\n",
    "    print(metric_str)\n",
    "    results = top_model_confusion(metric_str, results_cache_dir, model_cache_dir, eval_class=1)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "k2",
   "language": "python",
   "name": "k2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.insert(1, '/scr/gmachi/prospection/K2/src')\n",
    "from utils import deserialize_model, deserialize, serialize\n",
    "\n",
    "model_dir = \"/scr/gmachi/prospection/K2/notebooks/spatial-bio/outputs/gridsearch_results/k2models\"\n",
    "G_dir = \"/scr/biggest/gmachi/datasets/celldive_lung/for_ml/for_prospect/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid models: 208 / 232\n"
     ]
    }
   ],
   "source": [
    "valid_models = 0\n",
    "for model in os.listdir(model_dir):\n",
    "    model_str = os.path.join(model_dir, model)\n",
    "    if \"tau1.00\" not in model_str and \"tau2.00\" not in model_str:\n",
    "        try:\n",
    "            model = deserialize_model(model_str)\n",
    "            valid_models += 1\n",
    "        except EOFError:\n",
    "            print(\"skipping b/c corrupted:\", model)\n",
    "            continue\n",
    "\n",
    "print(\"valid models:\", valid_models, \"/\", len(os.listdir(model_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = \"/scr/biggest/gmachi/datasets/celldive_lung/processed/label_dict.obj\"\n",
    "label_dict = deserialize(label_path)\n",
    "# label_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run with prospection too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size_dict_path = \"/scr/gmachi/prospection/K2/notebooks/spatial-bio/tmp/size_dict.obj\"\n",
    "# dict_path = \"/scr/gmachi/prospection/K2/notebooks/spatial-bio/cc_stat_dict.obj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from test_signal import load_stat_dict\n",
    "# cc_stat_dict = load_stat_dict(dict_path)\n",
    "# len(cc_stat_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from test_signal import load_size_dict\n",
    "# cc_sizes = load_size_dict(size_dict_path)\n",
    "# # cc_sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_dir1 = \"/scr/gmachi/prospection/K2/notebooks/spatial-bio/tmp/class1\"\n",
    "# tmp_dir0 = \"/scr/gmachi/prospection/K2/notebooks/spatial-bio/tmp/class0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(os.listdir(model_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipdb\n",
    "from test_signal import analyze_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can run here but can also run over shell scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = \"/scr/biggest/gmachi/datasets/celldive_lung/analysis_cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed_set = set()\n",
    "for analysis_file in os.listdir(cache_dir):\n",
    "    model_str = analysis_file.split(\".\")\n",
    "    model_str = \".\".join(model_str[:-1])\n",
    "    analyzed_set.add(model_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(analyzed_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k10_r1_alpha10000000000.0000_tau0.00_lamnan\n",
      "k10_r1_alphanan_taunan_lam0.50\n",
      "k10_r2_alpha10000000000.0000_tau0.00_lamnan\n",
      "k10_r2_alphanan_taunan_lam0.50\n",
      "k10_r4_alphanan_taunan_lam0.50\n",
      "k10_r5_alpha10000000000.0000_tau0.00_lamnan\n",
      "k10_r5_alphanan_taunan_lam0.50\n",
      "k10_r6_alpha10000000000.0000_tau0.00_lamnan\n",
      "k10_r6_alphanan_taunan_lam0.50\n",
      "k10_r7_alpha10000000000.0000_tau0.00_lamnan\n",
      "k10_r7_alphanan_taunan_lam0.50\n",
      "k10_r8_alpha10000000000.0000_tau0.00_lamnan\n",
      "k10_r8_alphanan_taunan_lam0.50\n",
      "k11_r1_alphanan_taunan_lam0.50\n",
      "k11_r2_alpha10000000000.0000_tau0.00_lamnan\n",
      "k11_r4_alphanan_taunan_lam0.50\n",
      "k11_r5_alpha10000000000.0000_tau0.00_lamnan\n",
      "k11_r8_alphanan_taunan_lam0.50\n",
      "k12_r1_alphanan_taunan_lam0.50\n",
      "k12_r4_alphanan_taunan_lam0.50\n",
      "k12_r6_alphanan_taunan_lam0.50\n",
      "k12_r8_alphanan_taunan_lam0.50\n",
      "k13_r5_alphanan_taunan_lam0.50\n",
      "k13_r6_alpha10000000000.0000_tau0.00_lamnan\n",
      "k13_r7_alpha10000000000.0000_tau0.00_lamnan\n",
      "k13_r7_alphanan_taunan_lam0.50\n",
      "k14_r1_alpha10000000000.0000_tau0.00_lamnan\n",
      "k14_r1_alphanan_taunan_lam0.50\n",
      "k14_r2_alpha10000000000.0000_tau0.00_lamnan\n",
      "k14_r2_alphanan_taunan_lam0.50\n",
      "k14_r3_alpha10000000000.0000_tau0.00_lamnan\n",
      "k14_r3_alphanan_taunan_lam0.50\n",
      "k14_r4_alpha10000000000.0000_tau0.00_lamnan\n",
      "k14_r4_alphanan_taunan_lam0.50\n",
      "k14_r5_alpha10000000000.0000_tau0.00_lamnan\n",
      "k14_r5_alphanan_taunan_lam0.50\n",
      "k14_r6_alpha10000000000.0000_tau0.00_lamnan\n",
      "k14_r6_alphanan_taunan_lam0.50\n",
      "k14_r7_alphanan_taunan_lam0.50\n",
      "k14_r8_alpha10000000000.0000_tau0.00_lamnan\n",
      "k14_r8_alphanan_taunan_lam0.50\n",
      "k15_r1_alpha10000000000.0000_tau0.00_lamnan\n",
      "k15_r1_alphanan_taunan_lam0.50\n",
      "k15_r2_alpha10000000000.0000_tau0.00_lamnan\n",
      "k15_r2_alphanan_taunan_lam0.50\n",
      "k15_r3_alpha10000000000.0000_tau0.00_lamnan\n",
      "k15_r3_alphanan_taunan_lam0.50\n",
      "k15_r4_alpha10000000000.0000_tau0.00_lamnan\n",
      "k15_r4_alphanan_taunan_lam0.50\n",
      "k15_r5_alpha10000000000.0000_tau0.00_lamnan\n",
      "k15_r5_alphanan_taunan_lam0.50\n",
      "k15_r6_alpha10000000000.0000_tau0.00_lamnan\n",
      "k15_r7_alphanan_taunan_lam0.50\n",
      "k15_r8_alpha10000000000.0000_tau0.00_lamnan\n",
      "k15_r8_alphanan_taunan_lam0.50\n",
      "k16_r1_alpha10000000000.0000_tau0.00_lamnan\n",
      "k16_r1_alphanan_taunan_lam0.50\n",
      "k16_r2_alpha10000000000.0000_tau0.00_lamnan\n",
      "k16_r2_alphanan_taunan_lam0.50\n",
      "k16_r4_alpha10000000000.0000_tau0.00_lamnan\n",
      "k16_r4_alphanan_taunan_lam0.50\n",
      "k16_r5_alpha10000000000.0000_tau0.00_lamnan\n",
      "k16_r5_alphanan_taunan_lam0.50\n",
      "k16_r6_alpha10000000000.0000_tau0.00_lamnan\n",
      "k16_r7_alpha10000000000.0000_tau0.00_lamnan\n",
      "k16_r7_alphanan_taunan_lam0.50\n",
      "k16_r8_alpha10000000000.0000_tau0.00_lamnan\n",
      "k16_r8_alphanan_taunan_lam0.50\n",
      "k8_r1_alpha10000000000.0000_tau0.00_lamnan\n",
      "k8_r2_alpha10000000000.0000_tau0.00_lamnan\n",
      "k8_r2_alphanan_taunan_lam0.50\n",
      "k8_r3_alpha10000000000.0000_tau0.00_lamnan\n",
      "k8_r4_alpha10000000000.0000_tau0.00_lamnan\n",
      "k8_r4_alphanan_taunan_lam0.50\n",
      "k8_r5_alphanan_taunan_lam0.50\n",
      "k8_r6_alpha10000000000.0000_tau0.00_lamnan\n",
      "k8_r7_alpha10000000000.0000_tau0.00_lamnan\n",
      "k8_r7_alphanan_taunan_lam0.50\n",
      "k8_r8_alpha10000000000.0000_tau0.00_lamnan\n",
      "k8_r8_alphanan_taunan_lam0.50\n",
      "k9_r1_alpha10000000000.0000_tau0.00_lamnan\n",
      "k9_r2_alpha10000000000.0000_tau0.00_lamnan\n",
      "k9_r2_alphanan_taunan_lam0.50\n",
      "k9_r3_alphanan_taunan_lam0.50\n",
      "k9_r4_alphanan_taunan_lam0.50\n",
      "k9_r5_alpha10000000000.0000_tau0.00_lamnan\n",
      "k9_r5_alphanan_taunan_lam0.50\n",
      "k9_r6_alpha10000000000.0000_tau0.00_lamnan\n",
      "k9_r7_alpha10000000000.0000_tau0.00_lamnan\n",
      "k9_r7_alphanan_taunan_lam0.50\n",
      "k9_r8_alpha10000000000.0000_tau0.00_lamnan\n",
      "k9_r8_alphanan_taunan_lam0.50\n"
     ]
    }
   ],
   "source": [
    "for el in sorted(analyzed_set):\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a status dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# status_dict_path = \"/scr/gmachi/prospection/K2/notebooks/spatial-bio/status_dict.obj\"\n",
    "# status_dict = deserialize(status_dict_path)\n",
    "# for model_str in os.listdir(model_dir):\n",
    "#     if reset_flag == True:\n",
    "#         status_dict[model_str] = 0\n",
    "#     else:\n",
    "#         if model_str in status_dict.keys():\n",
    "#             continue\n",
    "#         else:\n",
    "#             status_dict[model_str] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize(status_dict, \"status_dict.obj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set(status_dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run loop over bash script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# status_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results_dir = \"/scr/biggest/gmachi/datasets/celldive_lung/analysis_cache/k8_r8_alphanan_taunan_lam0.50.embed1_dict\"\n",
    "# deserialize(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,model_str in enumerate(os.listdir(model_dir)):\n",
    "#     print(\"On model:\", i, \"/\", len(os.listdir(model_dir)), \":\", model_str)\n",
    "#     model_path = os.path.join(model_dir, model_str)\n",
    "    \n",
    "#     # check if valid model\n",
    "#     try:\n",
    "#         model = deserialize_model(model_path)\n",
    "#     except EOFError:\n",
    "#         print(\"Skipping b/c corrupted:\", model_str)\n",
    "#         continue\n",
    "    \n",
    "#     # check if model string in dictionary\n",
    "#     if model_str in cc_stat_dict.keys():\n",
    "#         print(\"Skipping b/c already analyzed:\", model_str)\n",
    "#         continue\n",
    "    \n",
    "#     analyze_model(model, model_str, label_dict, G_dir, tmp_dir1, tmp_dir0, size_dict_path, dict_path, debugging_flag=False, notebook_flag=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kkenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
